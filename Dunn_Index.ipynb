{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26880144b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#generating data\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "data = make_blobs(n_samples=10000, n_features=2, \n",
    "                           centers=2, cluster_std=0.8,random_state=101)\n",
    "plt.scatter(data[0][:,0],data[0][:,1],c=data[1],cmap='rainbow')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = pd.DataFrame(data[0])\n",
    "x['labels'] = data[1]\n",
    "x.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8428005602031243"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dunn(x['labels'], euclidean_distances(x.drop('labels', axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the diameters of all clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gabriel: AQUI!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, data[0] é o array das features, isto é, cada linha (ou elemento) de data[0] é uma tupla onde os elementos são as coordenadas do ponto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.26441293, 6.92916357])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][0] #isto é um ponto!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além disso, data[1] é o array das labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x recebe as features\n",
    "#labels recebe o array das labels\n",
    "\n",
    "labels = data[1]\n",
    "x = data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, label_1 recebe os índices, do array de labels, nos quais a label é 1, ou seja, os índices referentes ao cluster 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_1 = [i for i, e in enumerate(labels) if e == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 7,\n",
       " 14,\n",
       " 16,\n",
       " 19,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 27,\n",
       " 31,\n",
       " 35,\n",
       " 36,\n",
       " 44,\n",
       " 48,\n",
       " 51,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 64,\n",
       " 67,\n",
       " 69,\n",
       " 82,\n",
       " 88,\n",
       " 92,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 101,\n",
       " 102,\n",
       " 104,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 110,\n",
       " 116,\n",
       " 118,\n",
       " 119,\n",
       " 123,\n",
       " 125,\n",
       " 127,\n",
       " 130,\n",
       " 134,\n",
       " 142,\n",
       " 143,\n",
       " 146,\n",
       " 157,\n",
       " 159,\n",
       " 163,\n",
       " 164,\n",
       " 168,\n",
       " 172,\n",
       " 175,\n",
       " 178,\n",
       " 181,\n",
       " 189,\n",
       " 193,\n",
       " 205,\n",
       " 209,\n",
       " 210,\n",
       " 215,\n",
       " 216,\n",
       " 219,\n",
       " 222,\n",
       " 224,\n",
       " 225,\n",
       " 227,\n",
       " 230,\n",
       " 233,\n",
       " 234,\n",
       " 235,\n",
       " 239,\n",
       " 241,\n",
       " 243,\n",
       " 244,\n",
       " 247,\n",
       " 250,\n",
       " 253,\n",
       " 256,\n",
       " 257,\n",
       " 259,\n",
       " 261,\n",
       " 266,\n",
       " 273,\n",
       " 275,\n",
       " 279,\n",
       " 281,\n",
       " 283,\n",
       " 289,\n",
       " 296,\n",
       " 298,\n",
       " 301,\n",
       " 302,\n",
       " 303,\n",
       " 305,\n",
       " 306,\n",
       " 308,\n",
       " 309,\n",
       " 310,\n",
       " 312,\n",
       " 313,\n",
       " 314,\n",
       " 315,\n",
       " 317,\n",
       " 318,\n",
       " 322,\n",
       " 323,\n",
       " 325,\n",
       " 328,\n",
       " 329,\n",
       " 332,\n",
       " 333,\n",
       " 347,\n",
       " 351,\n",
       " 358,\n",
       " 359,\n",
       " 360,\n",
       " 361,\n",
       " 362,\n",
       " 363,\n",
       " 365,\n",
       " 366,\n",
       " 368,\n",
       " 371,\n",
       " 373,\n",
       " 374,\n",
       " 384,\n",
       " 387,\n",
       " 392,\n",
       " 396,\n",
       " 398,\n",
       " 399,\n",
       " 402,\n",
       " 403,\n",
       " 407,\n",
       " 411,\n",
       " 416,\n",
       " 417,\n",
       " 419,\n",
       " 420,\n",
       " 422,\n",
       " 424,\n",
       " 426,\n",
       " 436,\n",
       " 437,\n",
       " 442,\n",
       " 443,\n",
       " 444,\n",
       " 445,\n",
       " 450,\n",
       " 452,\n",
       " 454,\n",
       " 460,\n",
       " 461,\n",
       " 462,\n",
       " 463,\n",
       " 464,\n",
       " 465,\n",
       " 466,\n",
       " 468,\n",
       " 470,\n",
       " 471,\n",
       " 474,\n",
       " 478,\n",
       " 485,\n",
       " 487,\n",
       " 496,\n",
       " 500,\n",
       " 502,\n",
       " 506,\n",
       " 507,\n",
       " 508,\n",
       " 512,\n",
       " 515,\n",
       " 516,\n",
       " 520,\n",
       " 522,\n",
       " 525,\n",
       " 527,\n",
       " 530,\n",
       " 532,\n",
       " 534,\n",
       " 536,\n",
       " 538,\n",
       " 539,\n",
       " 543,\n",
       " 545,\n",
       " 548,\n",
       " 549,\n",
       " 550,\n",
       " 551,\n",
       " 552,\n",
       " 553,\n",
       " 555,\n",
       " 562,\n",
       " 564,\n",
       " 566,\n",
       " 567,\n",
       " 568,\n",
       " 570,\n",
       " 572,\n",
       " 573,\n",
       " 574,\n",
       " 577,\n",
       " 579,\n",
       " 582,\n",
       " 586,\n",
       " 587,\n",
       " 588,\n",
       " 590,\n",
       " 591,\n",
       " 592,\n",
       " 594,\n",
       " 600,\n",
       " 601,\n",
       " 603,\n",
       " 604,\n",
       " 609,\n",
       " 612,\n",
       " 614,\n",
       " 616,\n",
       " 618,\n",
       " 623,\n",
       " 624,\n",
       " 625,\n",
       " 626,\n",
       " 634,\n",
       " 636,\n",
       " 637,\n",
       " 638,\n",
       " 641,\n",
       " 642,\n",
       " 649,\n",
       " 654,\n",
       " 656,\n",
       " 657,\n",
       " 658,\n",
       " 661,\n",
       " 663,\n",
       " 664,\n",
       " 667,\n",
       " 671,\n",
       " 672,\n",
       " 677,\n",
       " 683,\n",
       " 684,\n",
       " 691,\n",
       " 693,\n",
       " 694,\n",
       " 702,\n",
       " 705,\n",
       " 707,\n",
       " 709,\n",
       " 710,\n",
       " 711,\n",
       " 715,\n",
       " 717,\n",
       " 719,\n",
       " 721,\n",
       " 723,\n",
       " 724,\n",
       " 729,\n",
       " 730,\n",
       " 734,\n",
       " 741,\n",
       " 743,\n",
       " 745,\n",
       " 746,\n",
       " 752,\n",
       " 758,\n",
       " 762,\n",
       " 767,\n",
       " 768,\n",
       " 769,\n",
       " 778,\n",
       " 783,\n",
       " 785,\n",
       " 789,\n",
       " 794,\n",
       " 803,\n",
       " 804,\n",
       " 805,\n",
       " 814,\n",
       " 819,\n",
       " 828,\n",
       " 830,\n",
       " 832,\n",
       " 834,\n",
       " 839,\n",
       " 847,\n",
       " 854,\n",
       " 855,\n",
       " 856,\n",
       " 857,\n",
       " 860,\n",
       " 861,\n",
       " 866,\n",
       " 867,\n",
       " 871,\n",
       " 872,\n",
       " 875,\n",
       " 876,\n",
       " 882,\n",
       " 887,\n",
       " 889,\n",
       " 897,\n",
       " 900,\n",
       " 901,\n",
       " 907,\n",
       " 909,\n",
       " 912,\n",
       " 913,\n",
       " 914,\n",
       " 917,\n",
       " 919,\n",
       " 923,\n",
       " 926,\n",
       " 928,\n",
       " 945,\n",
       " 949,\n",
       " 952,\n",
       " 957,\n",
       " 961,\n",
       " 964,\n",
       " 966,\n",
       " 972,\n",
       " 974,\n",
       " 980,\n",
       " 981,\n",
       " 984,\n",
       " 985,\n",
       " 986,\n",
       " 988,\n",
       " 997]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-12.06018828,  -7.61042468,   1.        ])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(cluster_1, (np.append(x[2], 1.0)))\n",
    "np.append(cluster_1, (np.append(x[7], 1.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aqui que não tá pegando!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#essa era a ideia para construir o cluster 1, mas não dá certo, essa merda fica retornando um array vazio\n",
    "cluster_1 = []\n",
    "cluster_1 = np.array(cluster_1)\n",
    "for i in label_1:\n",
    "    np.append(cluster_1, (np.append(x[i], 1.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def diameters(data, number_of_clusters): #testada\n",
    "    n_clusters = np.arange(0, number_of_clusters)\n",
    "    diameters = np.array([])\n",
    "    #for each cluster\n",
    "    for c in n_clusters:\n",
    "        distances = np.array([])\n",
    "        \n",
    "        cluster = df.loc[df['labels'] == c]\n",
    "        cluster.drop('labels', axis=1, inplace=True)\n",
    "        #calculates distance between all points in  the cluster\n",
    "        for i in range(len(cluster)):\n",
    "            for j in range(i+1, len(cluster)):\n",
    "                distances.append(euclidean(cluster.iloc[i,:], cluster.iloc[j,:]))\n",
    "        #appends the maximum distance between two points in the cluster,\n",
    "        #i.e., its diameter, to the list of diameters of all clusters\n",
    "        diameters.append(max(distances))\n",
    "    \n",
    "    return diameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster_midpoints(df, number_of_clusters):\n",
    "    #n_clusters = np.arange(0, number_of_clusters)\n",
    "    midpoints = []\n",
    "    \n",
    "    for c in range(number_of_clusters):\n",
    "        cluster = df.loc[df['labels'] == c]\n",
    "        cluster.drop('labels', axis=1, inplace=True)\n",
    "        midpoint = []\n",
    "        for i in range(len(cluster.columns)):\n",
    "            midpoint.append(np.mean(cluster.iloc[:,i]))\n",
    "        midpoints.append(midpoint)\n",
    "    \n",
    "    return midpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def midpoints_dist(df, number_of_clusters, minDist): #erro aqui!\n",
    "    midpoints = cluster_midpoints(df, number_of_clusters)\n",
    "    dist_midpoints = []\n",
    "    \n",
    "    for i in range(len(midpoints)):\n",
    "        for j in range(i+1, len(midpoints)):\n",
    "            dist_midpoints.append(euclidean(midpoints[i], midpoints[j]))\n",
    "    \n",
    "    if minDist == True:\n",
    "        return min(dist_midpoints)\n",
    "    else:\n",
    "        return dist_midpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-2d918cfe72ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmidpoints_dist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminDist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "midpoints_dist(df, 4, minDist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate general Dunn index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dunn_index(data, number_of_clusters):\n",
    "    dunn_index = midpoints_dist(df, 4, minDist=True)/max(diameters(df, number_of_clusters))\n",
    "    return dunn_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luan Brasil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "C:\\Users\\Luan Brasil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8433"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(dunn_index(df, 4), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A partir daqui: código da internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def normalize_to_smallest_integers(labels):\n",
    "    \"\"\"Normalizes a list of integers so that each number is reduced to the minimum possible integer, maintaining the order of elements.\n",
    "\n",
    "    :param labels: the list to be normalized\n",
    "    :returns: a numpy.array with the values normalized as the minimum integers between 0 and the maximum possible value.\n",
    "    \"\"\"\n",
    "\n",
    "    max_v = len(set(labels)) if -1 not in labels else len(set(labels)) - 1\n",
    "    sorted_labels = np.sort(np.unique(labels))\n",
    "    unique_labels = range(max_v)\n",
    "    new_c = np.zeros(len(labels), dtype=np.int32)\n",
    "\n",
    "    for i, clust in enumerate(sorted_labels):\n",
    "        new_c[labels == clust] = unique_labels[i]\n",
    "\n",
    "    return new_c\n",
    "\n",
    "\n",
    "def dunn(labels, distances):\n",
    "    \"\"\"\n",
    "    Dunn index for cluster validation (the bigger, the better)\n",
    "    \n",
    "    .. math:: D = \\\\min_{i = 1 \\\\ldots n_c; j = i + 1\\ldots n_c} \\\\left\\\\lbrace \\\\frac{d \\\\left( c_i,c_j \\\\right)}{\\\\max_{k = 1 \\\\ldots n_c} \\\\left(diam \\\\left(c_k \\\\right) \\\\right)} \\\\right\\\\rbrace\n",
    "    \n",
    "    where :math:`d(c_i,c_j)` represents the distance between\n",
    "    clusters :math:`c_i` and :math:`c_j`, given by the distances between its\n",
    "    two closest data points, and :math:`diam(c_k)` is the diameter of cluster\n",
    "    :math:`c_k`, given by the distance between its two farthest data points.\n",
    "    \n",
    "    The bigger the value of the resulting Dunn index, the better the clustering\n",
    "    result is considered, since higher values indicate that clusters are\n",
    "    compact (small :math:`diam(c_k)`) and far apart.\n",
    "\n",
    "    :param labels: a list containing cluster labels for each of the n elements\n",
    "    :param distances: an n x n numpy.array containing the pairwise distances between elements\n",
    "    \n",
    "    .. [Kovacs2005] Kovács, F., Legány, C., & Babos, A. (2005). Cluster validity measurement techniques. 6th International Symposium of Hungarian Researchers on Computational Intelligence.\n",
    "    \"\"\"\n",
    "\n",
    "    labels = normalize_to_smallest_integers(labels)\n",
    "\n",
    "    unique_cluster_distances = np.unique(min_cluster_distances(labels, distances))\n",
    "    max_diameter = max(diameter(labels, distances))\n",
    "\n",
    "    if np.size(unique_cluster_distances) > 1:\n",
    "        return unique_cluster_distances[1] / max_diameter\n",
    "    else:\n",
    "        return unique_cluster_distances[0] / max_diameter\n",
    "\n",
    "\n",
    "def min_cluster_distances(labels, distances):\n",
    "    \"\"\"Calculates the distances between the two nearest points of each cluster.\n",
    "\n",
    "    :param labels: a list containing cluster labels for each of the n elements\n",
    "    :param distances: an n x n numpy.array containing the pairwise distances between elements\n",
    "    \"\"\"\n",
    "    labels = normalize_to_smallest_integers(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "\n",
    "    min_distances = np.zeros((n_unique_labels, n_unique_labels))\n",
    "    for i in np.arange(0, len(labels) - 1):\n",
    "        for ii in np.arange(i + 1, len(labels)):\n",
    "            if labels[i] != labels[ii] and distances[i, ii] > min_distances[labels[i], labels[ii]]:\n",
    "                min_distances[labels[i], labels[ii]] = min_distances[labels[ii], labels[i]] = distances[i, ii]\n",
    "    return min_distances\n",
    "\n",
    "    \n",
    "def diameter(labels, distances):\n",
    "    \"\"\"Calculates cluster diameters (the distance between the two farthest data points in a cluster)\n",
    "\n",
    "    :param labels: a list containing cluster labels for each of the n elements\n",
    "    :param distances: an n x n numpy.array containing the pairwise distances between elements\n",
    "    :returns:\n",
    "    \"\"\"\n",
    "    labels = normalize_to_smallest_integers(labels)\n",
    "    n_clusters = len(np.unique(labels))\n",
    "    diameters = np.zeros(n_clusters)\n",
    "\n",
    "    for i in np.arange(0, len(labels) - 1):\n",
    "        for ii in np.arange(i + 1, len(labels)):\n",
    "            if labels[i] == labels[ii] and distances[i, ii] > diameters[labels[i]]:\n",
    "                diameters[labels[i]] = distances[i, ii]\n",
    "    return diameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.236243</td>\n",
       "      <td>-2.862409</td>\n",
       "      <td>-8.187646</td>\n",
       "      <td>6.178162</td>\n",
       "      <td>8.152271</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.523493</td>\n",
       "      <td>-8.182019</td>\n",
       "      <td>7.143758</td>\n",
       "      <td>4.040586</td>\n",
       "      <td>-6.629591</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.790533</td>\n",
       "      <td>-3.919686</td>\n",
       "      <td>7.164391</td>\n",
       "      <td>5.861425</td>\n",
       "      <td>-4.473478</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.354126</td>\n",
       "      <td>-4.800975</td>\n",
       "      <td>6.455403</td>\n",
       "      <td>1.790270</td>\n",
       "      <td>-4.971959</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.075494</td>\n",
       "      <td>-4.848203</td>\n",
       "      <td>7.312317</td>\n",
       "      <td>6.418761</td>\n",
       "      <td>-5.207236</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.148094</td>\n",
       "      <td>3.583692</td>\n",
       "      <td>-7.632100</td>\n",
       "      <td>-8.035919</td>\n",
       "      <td>1.157153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.560286</td>\n",
       "      <td>-6.644432</td>\n",
       "      <td>6.726596</td>\n",
       "      <td>2.913428</td>\n",
       "      <td>-7.911728</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.869713</td>\n",
       "      <td>-4.231725</td>\n",
       "      <td>7.459866</td>\n",
       "      <td>4.088911</td>\n",
       "      <td>-7.115475</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.498369</td>\n",
       "      <td>-3.371497</td>\n",
       "      <td>8.129171</td>\n",
       "      <td>4.304715</td>\n",
       "      <td>-7.685629</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.756843</td>\n",
       "      <td>-4.316828</td>\n",
       "      <td>6.625664</td>\n",
       "      <td>5.265476</td>\n",
       "      <td>-1.051138</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.507646</td>\n",
       "      <td>1.208515</td>\n",
       "      <td>-6.386827</td>\n",
       "      <td>-7.046021</td>\n",
       "      <td>2.794555</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.824554</td>\n",
       "      <td>-0.890721</td>\n",
       "      <td>-10.064290</td>\n",
       "      <td>-7.671660</td>\n",
       "      <td>2.445132</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.953841</td>\n",
       "      <td>5.079505</td>\n",
       "      <td>-7.728115</td>\n",
       "      <td>-6.081996</td>\n",
       "      <td>3.824653</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9.049758</td>\n",
       "      <td>-6.309873</td>\n",
       "      <td>8.673577</td>\n",
       "      <td>4.904892</td>\n",
       "      <td>-3.199827</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.501348</td>\n",
       "      <td>-7.185848</td>\n",
       "      <td>7.294909</td>\n",
       "      <td>8.454611</td>\n",
       "      <td>-7.748320</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.727325</td>\n",
       "      <td>2.248084</td>\n",
       "      <td>-9.906614</td>\n",
       "      <td>-10.269643</td>\n",
       "      <td>5.805087</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.371354</td>\n",
       "      <td>-3.089539</td>\n",
       "      <td>-5.518209</td>\n",
       "      <td>7.496005</td>\n",
       "      <td>12.205059</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.884995</td>\n",
       "      <td>-3.859711</td>\n",
       "      <td>4.164464</td>\n",
       "      <td>10.391368</td>\n",
       "      <td>-5.597893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.947488</td>\n",
       "      <td>-4.929257</td>\n",
       "      <td>6.579503</td>\n",
       "      <td>8.140887</td>\n",
       "      <td>-4.797177</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.401810</td>\n",
       "      <td>-0.614432</td>\n",
       "      <td>-7.715103</td>\n",
       "      <td>-8.650204</td>\n",
       "      <td>2.029742</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.967536</td>\n",
       "      <td>-3.435302</td>\n",
       "      <td>8.724919</td>\n",
       "      <td>2.512923</td>\n",
       "      <td>-7.876031</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.629762</td>\n",
       "      <td>-6.613676</td>\n",
       "      <td>-5.274277</td>\n",
       "      <td>4.047700</td>\n",
       "      <td>10.592772</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.611832</td>\n",
       "      <td>-2.032795</td>\n",
       "      <td>-8.312130</td>\n",
       "      <td>5.610098</td>\n",
       "      <td>10.466763</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.547840</td>\n",
       "      <td>-0.490174</td>\n",
       "      <td>-9.001374</td>\n",
       "      <td>-5.887530</td>\n",
       "      <td>3.243610</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.448245</td>\n",
       "      <td>4.412006</td>\n",
       "      <td>-6.223745</td>\n",
       "      <td>-7.553365</td>\n",
       "      <td>3.487909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7.106748</td>\n",
       "      <td>-5.209655</td>\n",
       "      <td>5.488094</td>\n",
       "      <td>7.720694</td>\n",
       "      <td>-9.008352</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4.798102</td>\n",
       "      <td>-4.309529</td>\n",
       "      <td>13.141484</td>\n",
       "      <td>5.448964</td>\n",
       "      <td>-4.358445</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.997528</td>\n",
       "      <td>-0.157025</td>\n",
       "      <td>-7.993746</td>\n",
       "      <td>-6.954546</td>\n",
       "      <td>2.126346</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.521163</td>\n",
       "      <td>-6.558883</td>\n",
       "      <td>9.990694</td>\n",
       "      <td>3.777688</td>\n",
       "      <td>-4.531851</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.003040</td>\n",
       "      <td>-5.211789</td>\n",
       "      <td>9.382977</td>\n",
       "      <td>7.619707</td>\n",
       "      <td>-8.850707</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>7.415265</td>\n",
       "      <td>-1.542278</td>\n",
       "      <td>5.675783</td>\n",
       "      <td>4.462560</td>\n",
       "      <td>-8.875245</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>1.826563</td>\n",
       "      <td>-5.327587</td>\n",
       "      <td>-6.627871</td>\n",
       "      <td>6.126694</td>\n",
       "      <td>13.818775</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>2.618605</td>\n",
       "      <td>-1.054626</td>\n",
       "      <td>-7.201434</td>\n",
       "      <td>6.032093</td>\n",
       "      <td>11.238680</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>8.926239</td>\n",
       "      <td>-4.472008</td>\n",
       "      <td>5.405185</td>\n",
       "      <td>2.052240</td>\n",
       "      <td>-6.677110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>5.932555</td>\n",
       "      <td>-4.307801</td>\n",
       "      <td>9.495482</td>\n",
       "      <td>7.605160</td>\n",
       "      <td>-4.048773</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>1.624681</td>\n",
       "      <td>-4.576691</td>\n",
       "      <td>-10.315667</td>\n",
       "      <td>-5.553659</td>\n",
       "      <td>2.978238</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>-2.857449</td>\n",
       "      <td>-3.493398</td>\n",
       "      <td>-5.300134</td>\n",
       "      <td>6.948266</td>\n",
       "      <td>8.138663</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>-1.544871</td>\n",
       "      <td>1.622416</td>\n",
       "      <td>-8.107123</td>\n",
       "      <td>-7.276946</td>\n",
       "      <td>6.369552</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>3.890526</td>\n",
       "      <td>-3.098163</td>\n",
       "      <td>9.567952</td>\n",
       "      <td>4.996914</td>\n",
       "      <td>-6.443712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>-0.417494</td>\n",
       "      <td>2.094720</td>\n",
       "      <td>-6.334975</td>\n",
       "      <td>-6.760790</td>\n",
       "      <td>8.108888</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>5.445720</td>\n",
       "      <td>-1.854500</td>\n",
       "      <td>-6.202207</td>\n",
       "      <td>3.613390</td>\n",
       "      <td>9.375802</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>-3.726198</td>\n",
       "      <td>1.666976</td>\n",
       "      <td>-10.395877</td>\n",
       "      <td>-7.909439</td>\n",
       "      <td>3.159293</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>0.847076</td>\n",
       "      <td>-1.086867</td>\n",
       "      <td>-4.629214</td>\n",
       "      <td>5.684890</td>\n",
       "      <td>6.938603</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>0.540936</td>\n",
       "      <td>-1.158135</td>\n",
       "      <td>-7.943304</td>\n",
       "      <td>-8.074867</td>\n",
       "      <td>-0.352892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>1.806861</td>\n",
       "      <td>-4.828746</td>\n",
       "      <td>-5.527230</td>\n",
       "      <td>6.516231</td>\n",
       "      <td>8.776805</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>1.972393</td>\n",
       "      <td>0.544008</td>\n",
       "      <td>-9.815064</td>\n",
       "      <td>-2.280894</td>\n",
       "      <td>4.907825</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>3.343031</td>\n",
       "      <td>-0.458402</td>\n",
       "      <td>-11.311336</td>\n",
       "      <td>-7.079100</td>\n",
       "      <td>1.144803</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>0.662139</td>\n",
       "      <td>3.489599</td>\n",
       "      <td>-8.145768</td>\n",
       "      <td>-3.606326</td>\n",
       "      <td>4.879190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>0.734423</td>\n",
       "      <td>5.182985</td>\n",
       "      <td>-11.037716</td>\n",
       "      <td>-4.692490</td>\n",
       "      <td>5.997298</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>4.304843</td>\n",
       "      <td>-1.216676</td>\n",
       "      <td>-8.147515</td>\n",
       "      <td>3.581880</td>\n",
       "      <td>8.033307</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>0.632388</td>\n",
       "      <td>-2.126104</td>\n",
       "      <td>-11.107024</td>\n",
       "      <td>-6.503165</td>\n",
       "      <td>4.100895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>0.044827</td>\n",
       "      <td>-5.033004</td>\n",
       "      <td>-8.850386</td>\n",
       "      <td>5.661705</td>\n",
       "      <td>8.600571</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>1.063883</td>\n",
       "      <td>0.537137</td>\n",
       "      <td>-5.930460</td>\n",
       "      <td>-7.692426</td>\n",
       "      <td>2.731527</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>7.005080</td>\n",
       "      <td>-0.315422</td>\n",
       "      <td>8.889514</td>\n",
       "      <td>4.892358</td>\n",
       "      <td>-7.789301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>-1.692174</td>\n",
       "      <td>-0.209728</td>\n",
       "      <td>-9.539133</td>\n",
       "      <td>-5.957608</td>\n",
       "      <td>1.759641</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>3.568274</td>\n",
       "      <td>-1.922386</td>\n",
       "      <td>-5.560624</td>\n",
       "      <td>1.827052</td>\n",
       "      <td>10.683602</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>6.950306</td>\n",
       "      <td>-1.750743</td>\n",
       "      <td>4.695463</td>\n",
       "      <td>4.398322</td>\n",
       "      <td>-6.205072</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2.026273</td>\n",
       "      <td>1.562144</td>\n",
       "      <td>-9.839584</td>\n",
       "      <td>-9.995883</td>\n",
       "      <td>1.232135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-0.820188</td>\n",
       "      <td>2.763105</td>\n",
       "      <td>-12.102443</td>\n",
       "      <td>-6.482068</td>\n",
       "      <td>3.000718</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-0.571446</td>\n",
       "      <td>-0.311442</td>\n",
       "      <td>-7.485888</td>\n",
       "      <td>-4.608083</td>\n",
       "      <td>7.696380</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1          2          3          4  labels\n",
       "0    0.236243 -2.862409  -8.187646   6.178162   8.152271       2\n",
       "1    1.523493 -8.182019   7.143758   4.040586  -6.629591       1\n",
       "2    3.790533 -3.919686   7.164391   5.861425  -4.473478       1\n",
       "3    2.354126 -4.800975   6.455403   1.790270  -4.971959       1\n",
       "4    7.075494 -4.848203   7.312317   6.418761  -5.207236       1\n",
       "5   -0.148094  3.583692  -7.632100  -8.035919   1.157153       0\n",
       "6    8.560286 -6.644432   6.726596   2.913428  -7.911728       1\n",
       "7    9.869713 -4.231725   7.459866   4.088911  -7.115475       1\n",
       "8    5.498369 -3.371497   8.129171   4.304715  -7.685629       1\n",
       "9    7.756843 -4.316828   6.625664   5.265476  -1.051138       1\n",
       "10   2.507646  1.208515  -6.386827  -7.046021   2.794555       0\n",
       "11   0.824554 -0.890721 -10.064290  -7.671660   2.445132       0\n",
       "12   1.953841  5.079505  -7.728115  -6.081996   3.824653       0\n",
       "13   9.049758 -6.309873   8.673577   4.904892  -3.199827       1\n",
       "14   4.501348 -7.185848   7.294909   8.454611  -7.748320       1\n",
       "15   1.727325  2.248084  -9.906614 -10.269643   5.805087       0\n",
       "16   1.371354 -3.089539  -5.518209   7.496005  12.205059       2\n",
       "17   9.884995 -3.859711   4.164464  10.391368  -5.597893       1\n",
       "18   5.947488 -4.929257   6.579503   8.140887  -4.797177       1\n",
       "19   2.401810 -0.614432  -7.715103  -8.650204   2.029742       0\n",
       "20   5.967536 -3.435302   8.724919   2.512923  -7.876031       1\n",
       "21   1.629762 -6.613676  -5.274277   4.047700  10.592772       2\n",
       "22   0.611832 -2.032795  -8.312130   5.610098  10.466763       2\n",
       "23   1.547840 -0.490174  -9.001374  -5.887530   3.243610       0\n",
       "24   1.448245  4.412006  -6.223745  -7.553365   3.487909       0\n",
       "25   7.106748 -5.209655   5.488094   7.720694  -9.008352       1\n",
       "26   4.798102 -4.309529  13.141484   5.448964  -4.358445       1\n",
       "27  -0.997528 -0.157025  -7.993746  -6.954546   2.126346       0\n",
       "28   2.521163 -6.558883   9.990694   3.777688  -4.531851       1\n",
       "29   5.003040 -5.211789   9.382977   7.619707  -8.850707       1\n",
       "..        ...       ...        ...        ...        ...     ...\n",
       "970  7.415265 -1.542278   5.675783   4.462560  -8.875245       1\n",
       "971  1.826563 -5.327587  -6.627871   6.126694  13.818775       2\n",
       "972  2.618605 -1.054626  -7.201434   6.032093  11.238680       2\n",
       "973  8.926239 -4.472008   5.405185   2.052240  -6.677110       1\n",
       "974  5.932555 -4.307801   9.495482   7.605160  -4.048773       1\n",
       "975  1.624681 -4.576691 -10.315667  -5.553659   2.978238       0\n",
       "976 -2.857449 -3.493398  -5.300134   6.948266   8.138663       2\n",
       "977 -1.544871  1.622416  -8.107123  -7.276946   6.369552       0\n",
       "978  3.890526 -3.098163   9.567952   4.996914  -6.443712       1\n",
       "979 -0.417494  2.094720  -6.334975  -6.760790   8.108888       0\n",
       "980  5.445720 -1.854500  -6.202207   3.613390   9.375802       2\n",
       "981 -3.726198  1.666976 -10.395877  -7.909439   3.159293       0\n",
       "982  0.847076 -1.086867  -4.629214   5.684890   6.938603       2\n",
       "983  0.540936 -1.158135  -7.943304  -8.074867  -0.352892       0\n",
       "984  1.806861 -4.828746  -5.527230   6.516231   8.776805       2\n",
       "985  1.972393  0.544008  -9.815064  -2.280894   4.907825       0\n",
       "986  3.343031 -0.458402 -11.311336  -7.079100   1.144803       0\n",
       "987  0.662139  3.489599  -8.145768  -3.606326   4.879190       0\n",
       "988  0.734423  5.182985 -11.037716  -4.692490   5.997298       0\n",
       "989  4.304843 -1.216676  -8.147515   3.581880   8.033307       2\n",
       "990  0.632388 -2.126104 -11.107024  -6.503165   4.100895       0\n",
       "991  0.044827 -5.033004  -8.850386   5.661705   8.600571       2\n",
       "992  1.063883  0.537137  -5.930460  -7.692426   2.731527       0\n",
       "993  7.005080 -0.315422   8.889514   4.892358  -7.789301       1\n",
       "994 -1.692174 -0.209728  -9.539133  -5.957608   1.759641       0\n",
       "995  3.568274 -1.922386  -5.560624   1.827052  10.683602       2\n",
       "996  6.950306 -1.750743   4.695463   4.398322  -6.205072       1\n",
       "997  2.026273  1.562144  -9.839584  -9.995883   1.232135       0\n",
       "998 -0.820188  2.763105 -12.102443  -6.482068   3.000718       0\n",
       "999 -0.571446 -0.311442  -7.485888  -4.608083   7.696380       0\n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from sklearn.datasets import load_iris\\nfrom sklearn.cluster import KMeans\\n\\nl = load_iris()\\nlabels = l['target']\\ndata = l['data']\\nk = KMeans(n_clusters=3).fit_predict(data)\\ndund = dunn(labels, euclidean_distances(data))\\ndunk = dunn(k, euclidean_distances(data))\\n\\n#print(x, c, dund, dunk)\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "l = load_iris()\n",
    "labels = l['target']\n",
    "data = l['data']\n",
    "k = KMeans(n_clusters=3).fit_predict(data)\n",
    "dund = dunn(labels, euclidean_distances(data))\n",
    "dunk = dunn(k, euclidean_distances(data))\n",
    "\n",
    "#print(x, c, dund, dunk)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#iris = pd.DataFrame(l['data'])\n",
    "#iris['labels'] = l['target']\n",
    "\n",
    "#iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luan Brasil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "C:\\Users\\Luan Brasil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8433480009754464"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dunn_index(data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
